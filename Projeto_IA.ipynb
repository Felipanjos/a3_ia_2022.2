{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felipanjos/a3_ia_2022.2/blob/main/Projeto_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "FGHweZQuwPte"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import sklearn\n",
        "from itertools import groupby\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('chip_dataset.csv', index_col=[0])\n",
        "df.drop('FP16 GFLOPS', axis=1, inplace=True)\n",
        "df.drop('FP32 GFLOPS', axis=1, inplace=True)\n",
        "df.drop('FP64 GFLOPS', axis=1, inplace=True)\n",
        "vendors = list(np.unique(df['Vendor']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_attribs = list(df.describe().columns)\n",
        "cat_attribs = ['Vendor']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B. Divisão "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### a) Amostragem estratificada em Conjunto de Treinamento e Conjunto de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "ranges = [0, df['Transistors (million)'].describe()['25%'], 500, 1000, 2000, 6000, 15000, 30000, np.inf]\n",
        "tiers = ['F', 'E', 'D', 'C', 'B', 'A', 'S', 'S+']\n",
        "\n",
        "df['Rank'] = pd.cut(df['Transistors (million)'], bins = ranges, labels = tiers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in splitter.split(df, df['Rank']):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "def amostragem_estratificada(test_set):\n",
        "    return (test_set['Rank'].value_counts() / len(test_set))*100    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "F     24.963504\n",
              "C     19.708029\n",
              "B     17.226277\n",
              "E     15.328467\n",
              "D     14.598540\n",
              "A      6.131387\n",
              "S      1.751825\n",
              "S+     0.291971\n",
              "Name: Rank, dtype: float64"
            ]
          },
          "execution_count": 278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "amostragem_estratificada(strat_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strat_train_set.drop(columns=['Rank'], inplace=True)\n",
        "strat_test_set.drop(columns=['Rank'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C. Exploração "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### a) Visualização dos Dados com gráficos de dispersão e histograma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Release Date'] = pd.to_datetime(df['Release Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ampliar escala \n",
        "strat_test_set['Transistors (million)'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strat_train_set['Transistors (million)'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.plot(kind='scatter', x='Release Date', y='Transistors (million)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### b. Levantamento de hipóteses sobre as distribuições dos dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### c. Busca de valueelações (Coeficientes de valueelação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Release Date'] = pd.to_numeric(df['Release Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3422 entries, 0 to 3421\n",
            "Data columns (total 11 columns):\n",
            " #   Column                 Non-Null Count  Dtype   \n",
            "---  ------                 --------------  -----   \n",
            " 0   Product                3422 non-null   object  \n",
            " 1   Type                   3422 non-null   object  \n",
            " 2   Release Date           3422 non-null   int64   \n",
            " 3   Process Size (nm)      3422 non-null   float64 \n",
            " 4   TDP (W)                3422 non-null   float64 \n",
            " 5   Die Size (mm^2)        3422 non-null   float64 \n",
            " 6   Transistors (million)  3422 non-null   float64 \n",
            " 7   Freq (MHz)             3422 non-null   float64 \n",
            " 8   Foundry                3422 non-null   object  \n",
            " 9   Vendor                 3422 non-null   object  \n",
            " 10  Rank                   3422 non-null   category\n",
            "dtypes: category(1), float64(5), int64(1), object(4)\n",
            "memory usage: 271.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Basearemos a análise das valueelações na coluna Transistors (million), que é o nosso objeto de predição"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Process Size (nm)',\n",
              " 'TDP (W)',\n",
              " 'Die Size (mm^2)',\n",
              " 'Transistors (million)',\n",
              " 'Freq (MHz)']"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_attribs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.002568951085001034\n",
            "-0.3977453283926615\n",
            "0.46970179480450375\n",
            "0.6402633611101106\n",
            "1.0\n",
            "-0.04411544348939104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anjos\\AppData\\Local\\Temp\\ipykernel_10336\\3423880030.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  for value in df.corr()['Transistors (million)']:\n"
          ]
        }
      ],
      "source": [
        "for value in df.corr()['Transistors (million)']:\n",
        "    print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coeficiente de correlação de Pearson entre a coluna Transistors (million) e:\n",
            "Release Date            -0.002569\n",
            "Process Size (nm)       -0.397745\n",
            "TDP (W)                  0.469702\n",
            "Die Size (mm^2)          0.640263\n",
            "Transistors (million)    1.000000\n",
            "Freq (MHz)              -0.044115\n",
            "Name: Transistors (million), dtype: float64 \n",
            "\n",
            "Release Date: relação linear negativa\n",
            "Process Size (nm): relação linear negativa\n",
            "TDP (W): relação linear positiva\n",
            "Die Size (mm^2): relação linear positiva\n",
            "Transistors (million): relação linear perfeita e positiva\n",
            "Freq (MHz): relação linear negativa\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anjos\\AppData\\Local\\Temp\\ipykernel_10336\\473720730.py:7: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  for value in df.corr()['Transistors (million)']:\n",
            "C:\\Users\\anjos\\AppData\\Local\\Temp\\ipykernel_10336\\473720730.py:21: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  print(df.corr(method='pearson', min_periods=1)['Transistors (million)'], '\\n')\n"
          ]
        }
      ],
      "source": [
        "colunas_para_calculo = ['Release Date'] + num_attribs\n",
        "print('Coeficiente de correlação de Pearson entre a coluna Transistors (million) e:')\n",
        "\n",
        "coor_dict = {}\n",
        "r_list = []\n",
        "\n",
        "for value in df.corr()['Transistors (million)']:\n",
        "    if value == 1:\n",
        "        r = 'relação linear perfeita e positiva'\n",
        "    elif value == 0:\n",
        "        r = 'inexistência linear'\n",
        "    elif value == -1:\n",
        "        r = 'relação linear perfeita e negativa'\n",
        "    elif value > 0:\n",
        "        r = 'relação linear positiva'\n",
        "    elif value < 0:\n",
        "        r = 'relação linear negativa'\n",
        "\n",
        "    r_list.append(r)\n",
        "\n",
        "print(df.corr(method='pearson', min_periods=1)['Transistors (million)'], '\\n')\n",
        "\n",
        "count = 0\n",
        "for col in colunas_para_calculo: \n",
        "    coor_dict[col] = r_list[count]\n",
        "    print(f'{col}: {coor_dict[col]}')\n",
        "    count += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### D. Preparação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np4v0J4Lb5p_"
      },
      "source": [
        "##### a) Selecionando 10% das colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No dataset utilizado existem somente 9 colunas, dessa forma:\n",
        "\n",
        "*    10% de 9 = 0.9\n",
        "*    Aproximando para 1, fica somente uma coluna a ser selecionada como referência para a modificação dos dados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q4KQCWnb8E0",
        "outputId": "9b709cec-a07f-4915-bfa5-26b318191d37"
      },
      "outputs": [],
      "source": [
        "qtd_colunas = len(df.columns)\n",
        "p_colunas = round(qtd_colunas * 10 / 100)\n",
        "coluna_aleatoria = df.sample(n=p_colunas, axis='columns').keys()[0]\n",
        "colunas_numericas = df.describe().columns\n",
        "colunas_categoricas = df.describe(exclude=np.number).columns\n",
        "coluna_aleatoria # escolhendo uma coluna aleatoriamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkopa3lohtjf"
      },
      "source": [
        "##### a) Selecionando 3% dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOtcB92hhvLg"
      },
      "outputs": [],
      "source": [
        "p_3 = int(df.shape[0] * 3 / 100)\n",
        "p_3 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ4KHum3skz7"
      },
      "source": [
        "##### a) Excluindo 3% dos dados aleatoriamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzSYvbRDysNe"
      },
      "outputs": [],
      "source": [
        "reg_nulos = df[df[coluna_aleatoria].isnull()]\n",
        "qtd_reg_nulos = reg_nulos.shape[0]\n",
        "reg_excluidos = df.sample(n=p_3)\n",
        "reg_exc_index = reg_excluidos.index.array\n",
        "df.loc[reg_exc_index, coluna_aleatoria] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxh3uWeotHrS"
      },
      "source": [
        "##### a) Alterando 3% dos dados aleatoriamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inRW488117mR"
      },
      "outputs": [],
      "source": [
        "def gerar_string_aleatoria():\n",
        "  letters = string.ascii_lowercase\n",
        "  return ''.join(random.choice(letters) for i in range(10)) \n",
        "\n",
        "def gerar_numero_aleatorio():\n",
        "  return random.randint(0, 999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMzmcXenuM7q"
      },
      "outputs": [],
      "source": [
        "df_selecao_nao_nulo = df[~df[coluna_aleatoria].isnull()]\n",
        "reg_alterados = df_selecao_nao_nulo.sample(n=p_3)\n",
        "reg_alter_index = reg_alterados.index.array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if coluna_aleatoria in colunas_numericas:\n",
        "    for index in reg_alter_index:\n",
        "        df.loc[[index],[coluna_aleatoria]] = gerar_numero_aleatorio()\n",
        "else:\n",
        "    for index in reg_alter_index:\n",
        "        df.loc[[index],[coluna_aleatoria]] = gerar_string_aleatoria()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### b) Limpeza dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "i. Codificação One-Hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder()\n",
        "onehot_encoded_df = pd.DataFrame(encoder.fit_transform(df[['Vendor']]).toarray())\n",
        "onehot_encoded_df.columns = vendors\n",
        "\n",
        "onehot_encoded_df = df.join(onehot_encoded_df)\n",
        "onehot_encoded_df.drop('Vendor', axis=1, inplace=True)\n",
        "onehot_encoded_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ii. Estratégia para dados numéricos ausentes - média"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A atribuição da mediana geral foi utilizada para lidar com os valores nulos das colunas em que existiam, pelos seguintes motivos:\n",
        "\n",
        "*   Número pequeno de colunas, logo a remoção completa de cada coluna em que houvesse valor nulo acarretaria na perda desnecessária de informações\n",
        "*   Facilidade na implementação em comparação com o treinamento de predição e atribuição\n",
        "*   Coesão com o dataset, visto que logo no primeiro quartil a coluna 'Meta_score' apresenta valor próximo à média\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iii. Escalonamento de características: Padronização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "iv. Pipeline transformadora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"mean\")),        \n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        ('num', num_pipeline, num_attribs),\n",
        "        ('cat', OneHotEncoder(), cat_attribs),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_prepared = full_pipeline.fit_transform(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "1411826be7eae97a21cd32c3ad68577137fa7ead80dc4d38e556535e3b8866d8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
